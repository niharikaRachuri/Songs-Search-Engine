{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithmic Methods of Data Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 3\n",
    "###  Andrea Aiello, Daniele Mocavini, Mani Niharika Rachuri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy\n",
    "import statistics\n",
    "from operator import itemgetter\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from collections import Counter\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First identify and save the folder where we have stored all the html files\n",
    "\n",
    "mypath = \"C:/Users/danie/OneDrive/Università/Data Science/Algorithmics (Aris-Yoannis)/Homeworks/Homework 3/aris database/lyrics_collection/\"\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we can parse the pages and take for each all the information we need, like artist, title, url and the song \n",
    "\n",
    "song={}\n",
    "song_list=[]\n",
    "artists_name_list=[]\n",
    "d = defaultdict(list)\n",
    "complete_dictionary=defaultdict(list)\n",
    "stringa=\"https://www.azlyrics.com/\"\n",
    "for i in onlyfiles:\n",
    "    file = open(\"C:/Users/danie/OneDrive/Università/Data Science/Algorithmics (Aris-Yoannis)/Homeworks/Homework 3/aris database/lyrics_collection/\"+ i, \"r\",encoding=\"utf8\")\n",
    "    soup = BeautifulSoup(file, 'lxml')\n",
    "    artist = soup.findAll(\"span\",{ \"class\" : \"item-header-color\" })\n",
    "    title = soup.findAll(\"h1\")\n",
    "    lyric = soup.findAll(\"div\", { \"class\" : \"dn\" })\n",
    "    try:\n",
    "        soup1 = BeautifulSoup(str(lyric[0]),'lxml')\n",
    "        l = soup1.text\n",
    "        t = str(title[0])\n",
    "        T = t[4:-12]\n",
    "        a = str(artist[2])\n",
    "        A = a[32:-14]\n",
    "        d[A].append(T)\n",
    "        song_list.append(l)\n",
    "        artists_name_list.append(A)\n",
    "        url=stringa+\"lyrics/\"+A.replace(\" \",\"\").lower()+\"/\"+T.replace(\" \",\"\").lower()+\".html\"\n",
    "        complete_dictionary[A,T].append([url, A, T, l])\n",
    "        song[T]=l\n",
    "        \n",
    "            \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For make a local copy of the lists and the dictionaries we created we choce to use numpy for his speed\n",
    "\n",
    "numpy.save(\"autori e canzoni\",d)\n",
    "numpy.save(\"D:/Download/solotesti\",song_list)\n",
    "numpy.save(\"nomiartisti\",artists_name_list)\n",
    "numpy.save(\"testi\",song)\n",
    "numpy.save(\"dizionario completo\", complete_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the local copy\n",
    "\n",
    "d=numpy.load(\"autori e canzoni.npy\").item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_list=numpy.load(\"D:/Download/solotesti.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "artists_name=numpy.load(\"nomiartisti.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "song=numpy.load(\"testi.npy\").item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictsongs=numpy.load(\"dizionario completo.npy\").item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert orderdict to dictionary and artist_name and song_list to a list\n",
    "\n",
    "d=dict(d)\n",
    "artists_name=list(artists_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "song_list=list(song_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store the parsed songs as documents in MongoDB database, one document per song,\n",
    "# using MongoDB Hosting: Database-as-a-Service by mLab\n",
    "\n",
    "dict_of_songs = [] #this will contain a list of dictionaries\n",
    "for [x,y] in dictsongs.keys():\n",
    "    #print(dictsongs[x,y])\n",
    "    a = dictsongs[x,y]\n",
    "    x=[]\n",
    "    x.append(a[0][0]) #url\n",
    "    x.append(a[0][1]) #artist\n",
    "    x.append(a[0][2]) #song name\n",
    "    x.append(a[0][3]) #lyrics\n",
    "    tempdict = {\"url\": x[0],\n",
    "                \"artist\": x[1],\n",
    "                \"song-name\": x[2],\n",
    "                \"lyrics\": x[3]\n",
    "            }\n",
    "    dict_of_songs.append(tempdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'apiKey': 'jJFk7bsNFjagIf9nvxRQzq4AhVot1kkK'}\n",
    "dbname = 'prova' #my db name in mlab\n",
    "\n",
    "collection = 'Algorithmic_Methods_of_Data_Mining_Hw3' #new collection created in mlab\n",
    "url = 'https://api.mlab.com/api/1/databases/' + dbname + '/collections/' + collection\n",
    "headers = {'content-type': 'application/json'}\n",
    "data = json.dumps(dict_of_songs[6:20])\n",
    "response = requests.post(url, data=data, params=params, headers=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Song Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Artist with most songs and create a histogram of the number of songs per Artist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This first function find the number of song for each artist\n",
    "\n",
    "def most_song (artist):\n",
    "    freq=[]\n",
    "    for i in artist:\n",
    "        a=(i,len((artist[i])))\n",
    "        freq.append(a)\n",
    "    return (freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# With a small change we can calculate also the mean\n",
    "\n",
    "def most_song_mean (artist):\n",
    "    freq=[]\n",
    "    for i in artist:\n",
    "        a=len(artist[i])\n",
    "        freq.append(a)\n",
    "    return (\"mean\", statistics.mean(freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# And also the median\n",
    "\n",
    "def most_song_median (artist):\n",
    "    freq=[]\n",
    "    for i in artist:\n",
    "        a=len(artist[i])\n",
    "        freq.append(a)\n",
    "    return (\"median\", statistics.median(freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find the number of song for each artist\n",
    "\n",
    "a=most_song(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finds the mean of the songs written by each artist\n",
    "\n",
    "med=most_song_mean(d)\n",
    "print(med)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finds the median of the songs written by each artist\n",
    "\n",
    "median=most_song_median(d)\n",
    "print(median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the histogram of the number of songs for artist\n",
    "\n",
    "df = pd.DataFrame(a, columns=['Artist Name', 'frequency'])\n",
    "frame1=df.plot(kind='bar', x='Artist Name')\n",
    "frame1.axes.get_xaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can also create an histogram ordered by number of songs written\n",
    "\n",
    "ordered_list=sorted(a,key=lambda x: x[1], reverse=True)\n",
    "df = pd.DataFrame(ordered_list, columns=['Artist Name', 'frequency'])\n",
    "frame1=df.plot(kind='bar', x='Artist Name')\n",
    "frame1.axes.get_xaxis().set_visible(False)\n",
    "\n",
    "plt.annotate('Mean', xy=(0,71.76514522821577), xytext=(200, 200),\n",
    "            arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "            )\n",
    "plt.annotate('Median', xy=(0,45), xytext=(500, 200),\n",
    "            arrowprops=dict(facecolor='orange', shrink=0.05),\n",
    "            )\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can also find the distribution\n",
    "\n",
    "more_200 = (\"More then 200\",sum(Counter([t[1] for t in ordered_list if t[1] > 200]).values()))\n",
    "equal200=(\"Equal 200\",sum(Counter([t[1] for t in ordered_list if t[1] == 200]).values()))\n",
    "a_150_to_200 = (\"From 150 to 200\",sum(Counter([t[1] for t in ordered_list if t[1] >= 100 and t[1] < 200 ]).values()))\n",
    "a_50_to_100 = (\"From 50 to 100\",sum(Counter([t[1] for t in ordered_list if t[1] >= 50 and t[1] < 100 ]).values()))\n",
    "a_25_to_50 = (\"From 25 to 50\",sum(Counter([t[1] for t in ordered_list if t[1] >= 25 and t[1] < 50 ]).values()))\n",
    "less_20 = (\"Less then 25\",sum(Counter([t[1] for t in ordered_list if t[1]  < 25]).values()))\n",
    "distribution=[more_200,equal200,a_150_to_200,a_50_to_100,a_25_to_50,less_20]\n",
    "df = pd.DataFrame(distribution, columns=['Distribution', 'frequency'])\n",
    "frame1=df.plot(kind='bar', x='Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inside Less then 25 group we have the following situation\n",
    "\n",
    "a_15_to_25 = (\"From 15 to 20\",sum(Counter([t[1] for t in ordered_list if t[1] >= 15 and t[1] < 25]).values()))\n",
    "a_10_to_15 = (\"From 10 to 15\",sum(Counter([t[1] for t in ordered_list if t[1] >= 10 and t[1] < 15]).values()))\n",
    "a_5_to_10 = (\"From 5 to 10\",sum(Counter([t[1] for t in ordered_list if t[1] >= 5 and t[1] < 10]).values()))\n",
    "less_5 = (\"Less then 5\",sum(Counter([t[1] for t in ordered_list if t[1]  < 5]).values()))\n",
    "equal2=(\"Equal 2\",sum(Counter([t[1] for t in ordered_list if t[1] == 2]).values()))\n",
    "equal1=(\"Equal 1\",sum(Counter([t[1] for t in ordered_list if t[1] == 1]).values()))\n",
    "distribution=[a_15_to_25,a_10_to_15,a_5_to_10,less_5,equal1,equal2]\n",
    "df = pd.DataFrame(distribution, columns=['Distribution', 'frequency'])\n",
    "frame1=df.plot(kind='bar', x='Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find who wrote more songs\n",
    "\n",
    "print(ordered_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we can also find the top 10 artist who have written more songs\n",
    "\n",
    "print(ordered_list[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# And also the first 25\n",
    "\n",
    "print(ordered_list[0:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the data we can first see the difference between mean (about 72) and median (45) so we can suppose to have some anomalous values.\n",
    "We have in fact that 501 Artist wrote less then 25 songs (of which 65 wrote just 1 song) ed just 37 wrote more then 200 songs, without these excesses we have that 191 artist wrote from 150 to 200 songs (262 artist if we include also the number 200 songs).\n",
    "\n",
    "In the top 10 most productive artist (excluding \"Various Artist\") we have just 1 band (Rolling Stones) and also looking at the first 25 we found just 1 other bad (U2), perhaps band's members have more frequently opposing views on songs and for this reason they write less or they melt.\n",
    "\n",
    "Interestingly also note how in the top 10 most productive artist (excluding \"Various Artist\") we have even 5 rapper.\n",
    "\n",
    "In the top 10 we also have 2 deceased artists (David Bowie and Frank Sinatra), searching for each the years active we have\n",
    "\n",
    "- Wiz Khalifa: 13 years\n",
    "- Rolling stone: 55 years\n",
    "- Snoop Dogg: 25 years\n",
    "- Chris Brown: 12 years\n",
    "- Elton John: 53 years\n",
    "- Frank Sinatra: 63 years\n",
    "- Dolly Parton: 58 years\n",
    "- Eminem: 25 years\n",
    "- David Bowie: 54 years\n",
    "- Lil Wayne: 20 years\n",
    "\n",
    "\n",
    "So the new ranking based on the number of songs written and years of activity is\n",
    "\n",
    "- Chris Brown: 17.25\n",
    "- Wiz Khalifa: 15.76\n",
    "- Lil Wayne: 10.55\n",
    "- Eminem: 8.40\n",
    "- Snoop Dogg: 8.24\n",
    "\n",
    "- Rolling stone: 7.74\n",
    "- Elton John: 3.92\n",
    "- David Bowie: 3.90\n",
    "- Dolly Parton: 3.60\n",
    "- Frank Sinatra: 3.13\n",
    "\n",
    "And again we can observe how rappers write many more songs than authors of other types of music \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify the 20 most popular words (exclude stopwords) and comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write a new txt files with songs without the most common stopwords of 17 different lenguage\n",
    "# we have also edited the \"english\" file adding the the following words:\n",
    "# \"dont\", \"cant\", \"youre\", \"aint\".\n",
    "# we have also decided to add the condition len(word) >=3 to delete other non-included stopwords\n",
    "# We chose to create a local copy of the new \"song file\" so that it can be analyzed at any time\n",
    "\n",
    "with open('outputFile.txt','w',encoding=\"utf8\") as outFile:\n",
    "    for line in song_list:\n",
    "        print(\" \".join([word for word in line.lower().translate(str.maketrans('', '', string.punctuation)).split() \n",
    "            if len(word) >=3 and word not in stopwords.words('arabic')\n",
    "                       and word not in stopwords.words('danish')\n",
    "                       and word not in stopwords.words('dutch')\n",
    "                       and word not in stopwords.words('english')\n",
    "                       and word not in stopwords.words('finnish')\n",
    "                       and word not in stopwords.words('french')\n",
    "                       and word not in stopwords.words('german')\n",
    "                       and word not in stopwords.words('hungarian')\n",
    "                       and word not in stopwords.words('italian')\n",
    "                       and word not in stopwords.words('kazakh')\n",
    "                       and word not in stopwords.words('norwegian')\n",
    "                       and word not in stopwords.words('portuguese')\n",
    "                       and word not in stopwords.words('romanian')\n",
    "                       and word not in stopwords.words('russian')\n",
    "                       and word not in stopwords.words('spanish')\n",
    "                       and word not in stopwords.words('swedish')\n",
    "                       and word not in stopwords.words('turkish')]), file=outFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we can read the output file and found the most common words\n",
    "\n",
    "with open('outputFile.txt',encoding=\"utf8\") as f:\n",
    "    passage = f.read()\n",
    "\n",
    "words = re.findall(r'\\w+', passage)\n",
    "common=Counter(words).most_common(20)\n",
    "print(common)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we found that the most used word is love, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify the 10 most common singer names (e.g, “Alice,” “Bob,” “Frank”) and see whether singers whose name is the same tend to publish more songs than others\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a nested list with name and suppose that the name of the artist is always the first word \n",
    "\n",
    "wo=[]\n",
    "for i in artists_name:\n",
    "    words = re.findall(r'\\w+', i)\n",
    "    wo.append(words)\n",
    "lst = [item[0] for item in wo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print the 10 most common name\n",
    "\n",
    "lst2=Counter(lst).most_common(10)\n",
    "print(lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We have also found \"The\", and we need to delete it and found again the most common\n",
    "\n",
    "lst2=Counter(lst).most_common(11)\n",
    "use=[x[0] for x in lst2]\n",
    "use.remove('The')\n",
    "print(use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remember the top 25 more productive artist\n",
    "\n",
    "aba=ordered_list[0:25]\n",
    "print(aba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select name and surname, create the frequence and concatenate\n",
    "\n",
    "woo=[]\n",
    "for i in [x[0] for x in aba]:\n",
    "    words = (re.findall(r'\\w+', i))\n",
    "    woo.append(words)\n",
    "\n",
    "test=[x[1] for x in aba]\n",
    "\n",
    "a=[x for x in zip(woo, test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find if there are 1 or more most common artist name in the top 25 most productive artist\n",
    "\n",
    "for i in use:\n",
    "    print((i,[item for item in a if item[0][0] == i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that 5 of the most common name (\"John\", \"Bob\", \"Neil\", \"Chris\" and \"Paul\") is in the top 25 of the most productive artist:\n",
    "\n",
    "- John Denver: 204\n",
    "- Bob Dylan: 205\n",
    "- Neil Young: 203\n",
    "- Chris Brown: 207\n",
    "- Paul McCartney: 205"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a histogram of song lengths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Found the title for each song\n",
    "titolo=[]\n",
    "for i in song:\n",
    "    titolo.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Count number of words in each songs\n",
    "\n",
    "num_words = [len(sentence.split()) for sentence in [value for value in song.values()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate\n",
    "unitaa=[x for x in zip(titolo, num_words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print the histogram\n",
    "\n",
    "df = pd.DataFrame(unitaa, columns=['Artist Name', 'frequency'])\n",
    "frame1=df.plot(kind='bar', x='Artist Name')\n",
    "frame1.axes.get_xaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# order the list by song's length\n",
    "\n",
    "ordered_unitaa=sorted(unitaa,key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can also find the distribution\n",
    "\n",
    "more_2000 = (\"More then 2000 words\",sum(Counter([t[1] for t in ordered_unitaa if t[1] > 2000]).values()))\n",
    "a_1000_to_2000 = (\"From 1000 to 2000 words\",sum(Counter([t[1] for t in ordered_unitaa if t[1] >= 1000 and t[1] < 2000 ]).values()))\n",
    "a_500_to_1000 = (\"From 500 to 1000 words\",sum(Counter([t[1] for t in ordered_unitaa if t[1] >= 500 and t[1] < 1000 ]).values()))\n",
    "a_250_to_500 = (\"From 250 to 500 words\",sum(Counter([t[1] for t in ordered_unitaa if t[1] >= 250 and t[1] < 500 ]).values()))\n",
    "a_100_to_250 = (\"From 100 to 250 words\",sum(Counter([t[1] for t in ordered_unitaa if t[1] >= 100 and t[1] < 250 ]).values()))\n",
    "a_50_to_100 = (\"From 50 to 100 words\",sum(Counter([t[1] for t in ordered_unitaa if t[1] >= 50 and t[1] < 100 ]).values()))\n",
    "less_50 = (\"Less then 50 words\",sum(Counter([t[1] for t in ordered_list if t[1]  < 50]).values()))\n",
    "distribution=[more_2000,a_1000_to_2000,a_500_to_1000,a_250_to_500,a_100_to_250,a_50_to_100,less_50]\n",
    "df = pd.DataFrame(distribution, columns=['Distribution', 'frequency'])\n",
    "frame1=df.plot(kind='bar', x='Distribution')\n",
    "plt.show()\n",
    "print(\"This is the distribution\", distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
